---
layout: post
title: Fundamental Data Analysis - Measures of Location and Variability
author: Ludovica
date: 2024-11-07 12:00:00 +0100
---

When we are faced with a vast amount of data, our initial objective is to make sense of it [1]. We achieve this by using **"descriptive statistics"** to summarize complex datasets into a few simple, understandable numbers [1]. These measures form the foundation for practical decision-making across numerous sectors [1]:

*   **In Business:** To understand the typical customer purchase value, average sales, or the consistency (or variability) of a manufacturing process [1].
*   **In Science:** To summarize experimental results, such as the central tendency of plant growth or the variability observed in a chemical reaction [2].
*   **In Economics:** To analyze market volatility (e.g., standard deviation) and income distribution (e.g., median income) [2].
*   **In Daily Life:** To understand factors like typical weather patterns or the spread of housing prices in a neighborhood [2].

This critical summarization process answers two fundamental questions regarding any dataset:

1.  Where is the "center" or typical value? (**Measures of Location**) [2, 3]
2.  How spread out or consistent is the data? (**Measures of Dispersion**) [3]

A dataset, such as a collection of test scores or house prices, can only be truly understood when both of these questions are answered [3].

## Part 1: Measures of Location (Central Tendency)

A measure of location, also known as central tendency, is a single value that attempts to describe a set of data by identifying the central position within that set [3]. It acts as a "summary" number that gives us a quick idea of the data's typical value [3].

This concept is ancient, but it gained **mathematical significance in the 17th and 18th centuries** [4]. This was primarily driven by early scientists, particularly those in astronomy and navigation, who needed a reliable way to combine multiple imperfect observations (such as the position of a star) to find the single most likely true value [4].

### 1. The Mean (Arithmetic Average)

**Definition:** The Mean is the most common measure of central tendency. It is simply the sum of all values in a dataset divided by the number of values [4].

**Historical Background:** Its formal application in statistics can be traced to 16th-century astronomers like **Tycho Brahe**, who averaged multiple measurements to reduce observation error [5]. It was later mathematically formalized by mathematicians such as **Abraham de Moivre** [5].

**When to Use:** The Mean is best for numerical data that is **symmetrically distributed** (like a bell curve), with no extreme values [6].

**Strengths:** Its main strength is that it uses every single value in the dataset, which makes it a comprehensive summary [6].

**Weaknesses:** It is **highly sensitive to outliers** (extremely high or low values) [6]. For example, in a small sample of salaries, a single $1 Million outlier can severely inflate the mean, making it unrepresentative of the individuals [6].

### 2. The Median

**Definition:** The Median is the middle value in a dataset that has been ordered from smallest to largest [7]. It is the **50th percentile**, meaning it is the point where half the data is above it and half is below [7].

**Historical Background:** The concept was introduced by French mathematician **Antoine Augustin Cournot** in 1843 and subsequently popularized by **Gustav Fechner** in the 1870s [7]. It gained prominence as a "robust" alternative to the mean, particularly in economic and social statistics where skewed data is common [7].

**How to Find:** You must first order the data [8]. If the number of values ($n$) is odd, the median is the single middle value; if $n$ is even, the median is the average of the two middle values [8].

**When to Use:** The Median is the preferred measure for data that is **skewed or has significant outliers** (such as house prices or income) [8].

**Strengths:** Its primary strength is its **robustness to outliers** [8]. In the salary example where the mean was distorted by an extreme value, the median remains a much more "typical" and representative value [8].

**Weaknesses:** Since it does not use all data points in its calculation, it can be considered less efficient mathematically than the mean [9].

### 3. The Mode

**Definition:** The Mode is the value that appears most frequently in a dataset [9].

**Historical Background:** The term "mode" was coined by English statistician **Karl Pearson** in 1895 [9]. He introduced it to identify the value with the highest frequency within probability distributions [9].

**Types:** A dataset can be Unimodal (one mode), Bimodal (two modes), Multimodal (more than two modes), or have No Mode (if all values appear with the same frequency) [9, 10].

**When to Use:** The Mode is the **only measure of central tendency** that is applicable to non-numerical or **categorical data** (such as "most common blood type" or "most popular car color") [10]. It is also useful for identifying frequency peaks in numerical data [10].

**Strengths:** It is simple to find and understand, and it works uniquely on nominal data [10].

**Weaknesses:** It is less useful for continuous numerical data (where exact values rarely repeat), and the possibility of having no mode or multiple modes can render it less definitive [10].

---

## Part 2: Measures of Dispersion (Variability)

Knowing the center of the data only tells half the story [11]. We must also understand how "spread out" the data is [11]. Measures of dispersion (or variability) describe the extent to which data points in a set differ from one another [11].

This measurement is crucial, as illustrated by two different classes having the same mean score of 75%: one class might have high consistency (low dispersion), while the other might have vastly different scores (high dispersion) [11]. Historically, this became vital in fields like **industrial quality control**, where high consistency (low dispersion) in parts is essential, not just the correct average size [12].

### 1. The Range

**Definition:** The Range is the simplest measure of dispersion, calculated as the difference between the highest and lowest values in the dataset [12].

**Historical Background:** This is one of the oldest and most intuitive measures of spread, having been used for centuries in basic data descriptions [12].

**Formula:** $Range = Maximum\ Value - Minimum\ Value$ [13].

**Strengths:** It is very simple to calculate and easy to understand [13].

**Weaknesses:** It is **extremely sensitive to outliers** [13]. Because the calculation uses only two data points, a single extreme value can provide a misleading picture of the dataâ€™s overall spread [13].

### 2. The Interquartile Range (IQR)

**Definition:** The Interquartile Range (IQR) is the range of the "middle 50%" of the data [13]. It is the difference between the third quartile (Q3) and the first quartile (Q1) [13].

**Historical Background:** The IQR was a key component of the box plot (or box-and-whisker plot), both of which were invented by the influential American statistician **John Tukey** in 1970 as part of his work on Exploratory Data Analysis (EDA) [13].

*   **Q1 (First Quartile):** The 25th percentile (the median of the lower half of the data) [14].
*   **Q3 (Third Quartile):** The 75th percentile (the median of the upper half of the data) [14].

**Formula:** $IQR = Q3 - Q1$ [14].

**When to Use:** The IQR is considered the **perfect partner for the Median** [14]. If your data is skewed or contains outliers, the Median and IQR are the best measures to describe both the center and the spread [14].

**Strengths:** Like the median, the IQR is **robust to outliers** [14]. It describes the spread of the bulk of the data while ignoring the extremes [14].

### 3. The Variance

**Definition:** The Variance is a sophisticated measure of dispersion defined as the average of the squared differences from the Mean [15]. It measures, on average, how far each number in the set deviates from the mean [15].

**Historical Background:** The concept of variance emerged from work on the method of least squares by **Legendre** (1805) and **Gauss** (1809) [15]. The term "variance" itself was formally introduced by **Ronald Fisher** in his 1918 paper [15].

**Note on $n-1$ (Bessel's Correction):** When calculating sample variance, dividing by $n-1$ instead of $n$ is known as **"Bessel's correction."** This correction makes the sample variance a more accurate, unbiased estimator of the true population variance [16].

**Strengths:** It utilizes all data points and is fundamental to many advanced statistical tests, such as ANOVA [16].

**Weaknesses:** The units are squared (e.g., if measuring in "dollars," the variance is in "squared dollars"), which makes it non-intuitive to interpret [16].

### 4. The Standard Deviation (SD)

**Definition:** The Standard Deviation is the single most common and important measure of dispersion [17]. It is calculated as the square root of the Variance [17]. Conceptually, it represents the typical or average distance of a data point from the mean [17].

**Historical Background:** The term "standard deviation" was introduced by **Karl Pearson** in 1894 [17]. He proposed it because taking the square root made the measure more convenient and interpretable by returning it to the original unit of measurement [17].

**Strengths:**
*   **Interpretable:** The unit matches the original data (e.g., "dollars") [17].
*   **Powerful (Empirical Rule):** For normally distributed data (a bell curve), approximately **68%** of data falls within 1 standard deviation of the mean, **95%** falls within 2 standard deviations, and **99.7%** falls within 3 standard deviations [17, 18].

**Weaknesses:** Like the mean and variance, the standard deviation is sensitive to outliers [18].

## Conclusion: Pairing Measures

To achieve a full picture of your data, you should always use both a center measure and a spread measure [18, 19]. The best combination to use depends on the data's distribution [19]:

| Data Distribution | Best Measure of Location (Center) | Best Measure of Dispersion (Spread) |
| :--- | :--- | :--- |
| **Symmetrical (no outliers)** | Mean | Standard Deviation [19] |
| **Skewed (with outliers)** | Median | Interquartile Range (IQR) [19] |